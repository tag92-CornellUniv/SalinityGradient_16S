---
title: "Infer ASVs with DADA2"
output: html_document
toc: yes
toc_float: 
  collapsed: no
  smooth_scroll: yes
  toc_depth: 3
date: "2024-02-21"
editor_options: 
  chunk_output_type: console
---
#Before you start

##Set my seed
```{r set-seed}
#Setting our seed: makes the code reproducible; will pick the same random samples (the ones we used to generate the quality plots)

#Any number can be chosen 
set.seed(02262000)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      fig.align = "center",
                      fig.path = "../figures/01_DADA2/")#send any figure output to this folder
```


# Goals of this file

1. use raw fastq files and generate the quality plots to assess quality of reads
2. filter and trim out bad sequences and bases from our raw sequencing files
3. Write out fastq files with high quality sequences
4. Evaluate the quality from our filter and trim
5. Generate error models
6. Identified ASVs for forward and reverse reads separately
7. Merge forward and reverse ASVs
8. Generate ASV count table (will be the otu table input for phyloseq)

Output that we need:

1.ASV Count table: otu_table
2. Taxonomy Table: tax_table
3. Sample Information: "sample_data" track the reads lots throughout the DADA2 workflow
#load libraries
```{r Load-libraries}

#library(devtools)

#install.packages("dada2")
library(dada2)

#install.packages("tidyverse")
library(tidyverse)
```

# Load Data
```{r load-data}
# Set the raw fastq paths to the raw sequencing files
#Path to the fastq files
raw_fastqs_path <- "data/01_DADA2/01_rawgzipped_fastqs/"
raw_fastqs_path

#What files are in this path? Intuition Check
list.files(raw_fastqs_path) 


#how many files are there?
str(list.files(raw_fastqs_path))

#Create vector of forward reads
#forward_reads <- 
  
forward_reads <- list.files(raw_fastqs_path, pattern = "R1_001.fastq.gz", full.names = TRUE)
head(forward_reads)

#Create vector of reverse reads
reverse_reads <- list.files(raw_fastqs_path, pattern = "R2_001.fastq.gz", full.names = TRUE)
head(reverse_reads)

```

# Quality Plots
```{r raw-quality-plots}
# randomly select two samples for each dataset to evaluate
random_samples <- sample(1:length(reverse_reads), size = 2)
random_samples

#calculate and plot quality of htese two samples
plotQualityProfile(forward_reads[random_samples])
plotQualityProfile(reverse_reads[random_samples])
```

#Prepare a placeholder for filtered reads
```{r prep-filtered-sequences}
#vector for samples, extract sample name from files
samples <- sapply(strsplit(basename(forward_reads), "_"), `[`,1)
head(samples)

# Place filtered reads into filtered_fastqs_path
filtered_fastqs_path <- "data/01_DADA2/02_filtered_fastqs"

# Create 2 variables: filtered_F, filtered_R
filtered_forward_reads <- file.path(filtered_fastqs_path, paste0(samples, "_R1_filtered.fastq.gz"))
length(filtered_forward_reads)

filtered_reverse_reads <- file.path(filtered_fastqs_path, paste0(samples, "_R2_filtered.fastq.gz"))
head(filtered_reverse_reads)
```



#Filter and Trim

Parameters of filter and trim depend on the DATA SET
Kozich et al. -> describe library prep and a protocol where they used 515F and 806R primers for full overlap
2 step illumina: you need to remove the primers
Does my dataset include the primers? Read the methods paper. 
Pair ended reads are better, so there are forward and reverse reads
```{r filter-and-trim}
?filterAndTrim
#maxN= the number of n bases. Putting zeros removes Ns from the data. Every base matters.
#maxEE = expected errors. quality filtering threshold applied to expected errors. here, if there are less than 2 errors, its okay. However, more than two would result in the data being discarded. First value is for the forward read, the second is for the reverse read.
#trimLeft = remove first three basepairs 

#Assign a vector to filtered reads
#trim out poor bases, first 3 bp on F reads
#write out filtered fastq files
filtered_reads <- filterAndTrim(fwd = forward_reads, filt = filtered_forward_reads, rev = reverse_reads, filt.rev = filtered_reverse_reads, maxN = 0, maxEE = c(2,2), trimLeft= 3, truncQ = 2, rm.phix = TRUE, compress = TRUE) #multithread = TRUE)


```
#Trimmed quality plots
```{r filterTrim-quality-plots}
plotQualityProfile(filtered_forward_reads[random_samples]) + 
  labs(title = "Trimmed Forward Quality")

plotQualityProfile(filtered_reverse_reads[random_samples]) + 
  labs(title = "Trimmed Reverse Quality")


```

#Aggregated Trimmed Plots
```{r}
#aggregate all QC plots
plotQualityProfile(filter_forward_reads, aggregate = TRUE) +
  plotQualityProfile(filter_reverse_reads, aggregate = TRUE)

```

#Stats on read outpur from "filterandTrim"
```{r filterTrim-stats}
filtered_df <- as.data.frame(filtered_reads)
head(filtered_df)


filtered_df %>%
  reframe(median_reads_in = median(reads.in),
          median_reads_out = median(reads.out),
          median_percent_retained = (median(reads.out)/median(reads.in)))

```

#error Modelling

**NOTE: Run separately on each dataset
```{r learn-errors}
#run on the forward reads
error_forward_reads <- 
  learnErrors(filtered_forward_reads) # multithread = TRUE

#run on the reverse reads
error_reverse_reads <- 
  learnErrors(filtered_reverse_reads) # multithread = TRUE

plotErrors(error_forward_reads, nominalQ = TRUE) + 
  labs(title = "Forward Read Error Model")

plotErrors(error_reverse_reads, nominalQ = TRUE) + 
  labs(title = "Reverse Read Error Model")
```

#Infer ASVs

Note that this is happening separately on the forward and reverse reads. This is unique to DADA2.
```{r infer-ASVs}
#Infer forward reads
dada_forward <- dada(filtered_forward_reads, err = error_forward_reads) #multithread = TRUE

#Infer reverse reads
dada_reverse 
dada_reverse <- dada(filtered_reverse_reads, err = error_reverse_reads) #multithread = TRUE

```

#Merge Forward and Reverse ASVs
```{r merge-ASVs}
#merge forward and reverse ASVs
merged_ASVs <- mergePairs(dada_forward, filtered_forward_reads,
                          dada_reverse, filtered_reverse_reads,
                          verbose = TRUE)

#Evaluate the output 
typeof(merged_ASVs)
length(merged_ASVs)
names(merged_ASVs)
```

#Generate ASV Count Table
```{r generate-ASV-table}
#Create the ASV Count table
raw_ASV_table <- makeSequenceTable(merged_ASVs)

#Write out the file to data/01_DADA2 

```

#Session information
```{r session-info}
devtools::session_info()


```

